{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE tranining\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import theano\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython import display\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "data = pd.read_excel('Traning dataset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define one_hot_encoding\n",
    "\n",
    "def one_hot_encoding(df, seq_column, expression):\n",
    "    bases = ['A','C','G','T']\n",
    "    base_dict = dict(zip(bases,range(4)))\n",
    "    n = len(df)\n",
    "    total_width = df[seq_column].str.len().max()+20\n",
    "    X = np.zeros((n,1,4,total_width))\n",
    "    seqs = df[seq_column].values\n",
    "    for i in range(n):\n",
    "        seq = seqs[i]\n",
    "        for b in range(len(seq)):\n",
    "            X[i,0,base_dict[seq[b]], b+10+50-len(seq)] = 1    \n",
    "    X = X.astype(theano.config.floatX)\n",
    "    return X, total_width\n",
    "\n",
    "X, total_width = one_hot_encoding(data,'Promoter','Reads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build VAE frame\n",
    "\n",
    "class CVAE(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(1,4,70)),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=16, kernel_size=(4,35), strides=(1, 1), activation='relu',data_format = 'channels_first'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=16, kernel_size=(1,21), strides=(1, 1), activation='relu',data_format = 'channels_first'),\n",
    "                tf.keras.layers.Conv2D(\n",
    "                    filters=16, kernel_size=(1,15), strides=(1, 1), activation='relu',data_format = 'channels_first'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.decoder = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "                tf.keras.layers.Dense(units=1*4*120, activation=tf.nn.relu),\n",
    "                tf.keras.layers.Reshape(target_shape=(1, 4, 120)),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, kernel_size=(1,15), strides=(1,1), padding='same',\n",
    "                    activation='relu',data_format = 'channels_first'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, kernel_size=(1,21), strides=(1,1), padding='same',\n",
    "                    activation='relu',data_format = 'channels_first'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=16, kernel_size=(1,35), strides=(1,1), padding='same',\n",
    "                    activation='relu',data_format = 'channels_first'),\n",
    "                tf.keras.layers.Conv2DTranspose(\n",
    "                    filters=1, kernel_size=(4,29), strides=1, padding='same', data_format = 'channels_first'),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def sample(self, eps=None):\n",
    "        if eps is None:\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "        return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "    def encode(self, x):\n",
    "        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "        return mean, logvar\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        eps = tf.random.normal(shape=mean.shape)\n",
    "        return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "    def decode(self, z, apply_sigmoid=False):\n",
    "        logits = self.decoder(z)\n",
    "        if apply_sigmoid:\n",
    "            probs = tf.sigmoid(logits)\n",
    "            return probs\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define loss function & train step\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    \n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    \n",
    "    mean, logvar = model.encode(x)\n",
    "    z = model.reparameterize(mean, logvar)\n",
    "    x_logit = tf.dtypes.cast(model.decode(z),tf.float64)\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "    logpz = tf.dtypes.cast(log_normal_pdf(z, 0., 0.),tf.float64)\n",
    "    logqz_x = tf.dtypes.cast(log_normal_pdf(z, mean, logvar),tf.float64)\n",
    "    \n",
    "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(model, x)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Set up a model\n",
    "\n",
    "epochs = 1000\n",
    "latent_dim = 2\n",
    "num_examples_to_generate = 10000\n",
    "random_vector_for_generation = tf.random.normal(\n",
    "    shape=[num_examples_to_generate, latent_dim])\n",
    "model = CVAE(latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 5. Model training\n",
    "\n",
    "X = np.expand_dims(X,axis = 0)\n",
    "\n",
    "elbolist = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "    for tot_X in X:\n",
    "        train_step(model, tot_X, optimizer)\n",
    "    end_time = time.time()\n",
    "\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    for tot_X in X:\n",
    "        loss(compute_loss(model, tot_X))\n",
    "    elbo = -loss.result()\n",
    "    elbolist.append(elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Save model\n",
    "\n",
    "model.encoder.save('cyano_encode.h5')\n",
    "model.decoder.save('cyano_decode.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
